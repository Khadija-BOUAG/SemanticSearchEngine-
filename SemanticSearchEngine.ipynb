{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemanticSearchEngine Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import Libraries & Data"
      ],
      "metadata": {
        "id": "inR1elSEFwf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "o5KjwJSpF2dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from nltk import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDIh4T7KF5vR",
        "outputId": "f7165e4c-1868-4b81-dac3-fb2cd70a5c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_agpDFURIq-",
        "outputId": "dad9982d-92f4-41fe-e3b1-0ab6b164d638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/semantic\\ search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qajvy3PPRSDo",
        "outputId": "35b71cd6-d9cf-45d3-b794-92756da0dc58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/semantic search\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of conversations\n",
        "df = pd.read_excel('data.xlsx')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "c2GmwTQhGBC5",
        "outputId": "09444210-b058-4bc8-9f5f-85e0aa85aa26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ee588ac9-bc76-493e-8851-399f27ad0b08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We are seeing an increasing number of errors w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>We need to make improvements to our landing pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It looks like the issue is limited only to vis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We need to schedule a product meeting to discu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee588ac9-bc76-493e-8851-399f27ad0b08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee588ac9-bc76-493e-8851-399f27ad0b08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee588ac9-bc76-493e-8851-399f27ad0b08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                           Sentences\n",
              "0  We are seeing an increasing number of errors w...\n",
              "1  We need to make improvements to our landing pa...\n",
              "2  It looks like the issue is limited only to vis...\n",
              "3  We need to schedule a product meeting to discu..."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NB :** the following data is for the second approach "
      ],
      "metadata": {
        "id": "js69TUTqHlK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import Quora Question Pairs dataset\n",
        "quora = pd.read_csv('train.csv')\n",
        "quora.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YNDQCWjQHt-C",
        "outputId": "1fc2ff28-2936-4b41-a990-370ad4de2519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-eb79ed73-970d-4c1d-b3ad-6df06f07b9ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb79ed73-970d-4c1d-b3ad-6df06f07b9ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb79ed73-970d-4c1d-b3ad-6df06f07b9ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb79ed73-970d-4c1d-b3ad-6df06f07b9ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Text Pre-Processing"
      ],
      "metadata": {
        "id": "ak8BADYIFqJF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOdVjGJdFm5q"
      },
      "outputs": [],
      "source": [
        "def process(paragraph) :\n",
        "  ps = PorterStemmer()\n",
        "  corpus = []\n",
        "  try :\n",
        "    par = paragraph.values\n",
        "  except :\n",
        "    par = paragraph\n",
        "  for text in par :\n",
        "      #accept any uppercase or lowercase letters \n",
        "      cleaned = re.sub('[^a-zA-Z]', ' ', str(text))\n",
        "\n",
        "      #get lowercase of all words in corpus\n",
        "      \n",
        "      cleaned = cleaned.lower().split()\n",
        "      \n",
        "      #remove stopwords + stemming \n",
        "      cleaned = [ps.stem(word) for word in cleaned if not word in stopwords.words('english')]\n",
        "      cleaned = ' '.join(cleaned)\n",
        "      corpus.append(cleaned)\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. First Approach = DistilBERT + Cosine Similarity"
      ],
      "metadata": {
        "id": "HZ6FID6QGLDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelB = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')"
      ],
      "metadata": {
        "id": "WpEMhCBzGQwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We embed our conversations :"
      ],
      "metadata": {
        "id": "ljh5q2kTG1OJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = df.iloc[:, 0] \n",
        "corpus = process(paragraph)\n",
        "embeddings_distilbert = modelB.encode(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_jWspadGW_m",
        "outputId": "e6d932e1-9567-4493-ce13-e8a4c9165964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 96.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We embed our search query :"
      ],
      "metadata": {
        "id": "K9yuvSktG9qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_string = \"failed payments\"\n",
        "search_vect = modelB.encode([search_string])"
      ],
      "metadata": {
        "id": "T79wBCpsGdlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's find now the similarity between vectors using cosine similarity function :"
      ],
      "metadata": {
        "id": "UcPeHP-xGjvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar(query, conversations, k=1):\n",
        "    similarity_matrix = cosine_similarity(query, conversations)\n",
        "\n",
        "    similarities = similarity_matrix[0]\n",
        "    #print(similarities)\n",
        "\n",
        "    # we get the more relevant conversations\n",
        "    if k == 1:\n",
        "        return [np.argmax(similarities)]\n",
        "    elif k is not None:\n",
        "        return np.flip(similarities.argsort()[-k:][::1]) "
      ],
      "metadata": {
        "id": "W-w-fEzWGlnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = 2 # no. of conversations that has to be returned, for now we choose 2 conversations\n",
        "distilbert_similar_indexes = get_similar(search_vect, embeddings_distilbert, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy4xOvO2Gp5p",
        "outputId": "05ad6b51-04ab-485b-ff28-47cee6de8aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.13662694 -0.04744482  0.04145075 -0.05135897]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_data = []\n",
        "for index in distilbert_similar_indexes:\n",
        "    output_data.append(paragraph[index])"
      ],
      "metadata": {
        "id": "H2apIeHuGs2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWz883EJGw3i",
        "outputId": "d6afcd16-b415-49a8-f920-6eaf209bfc40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We are seeing an increasing number of errors with our payment services. The\\nissue has been reported by multiple users in the last 3 hours and this is affecting\\nour revenue. We need to fix it immediately',\n",
              " 'It looks like the issue is limited only to visa credit cards']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Highlight the results"
      ],
      "metadata": {
        "id": "dwBs2OSjdABZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Highlight the whole relevant conversation between the other ones :"
      ],
      "metadata": {
        "id": "FpD0FFSmM2fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA3Vf_Yykc8x",
        "outputId": "7904a14a-1582-47c7-e14c-3aa851593558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['We are seeing an increasing number of errors with our payment services. The\\nissue has been reported by multiple users in the last 3 hours and this is affecting\\nour revenue. We need to fix it immediately',\n",
              "       'We need to make improvements to our landing page to convey our new\\nbranding guidelines.',\n",
              "       'It looks like the issue is limited only to visa credit cards',\n",
              "       'We need to schedule a product meeting to discuss the new set of features and\\nthe roadmap.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from termcolor import colored\n",
        "\n",
        "for elt in paragraph.values :\n",
        "    if elt in output_data:\n",
        "        print(colored(elt,'white','on_green'))\n",
        "    else :\n",
        "        print(elt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCYNF69JczzM",
        "outputId": "6d886013-e2e8-448e-f0a1-0004f4ad13c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[42m\u001b[37mWe are seeing an increasing number of errors with our payment services. The\n",
            "issue has been reported by multiple users in the last 3 hours and this is affecting\n",
            "our revenue. We need to fix it immediately\u001b[0m\n",
            "We need to make improvements to our landing page to convey our new\n",
            "branding guidelines.\n",
            "\u001b[42m\u001b[37mIt looks like the issue is limited only to visa credit cards\u001b[0m\n",
            "We need to schedule a product meeting to discuss the new set of features and\n",
            "the roadmap.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Highlight just the relevant sentence in search results :"
      ],
      "metadata": {
        "id": "8_38Sr97M-_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for t in output_data :\n",
        "  sentences = sent_tokenize(t)\n",
        "  sentences_ = process(sentences)\n",
        "  sentences_ = modelB.encode(sentences_)\n",
        "  sen = get_similar(search_vect, sentences_, 1)\n",
        "  rel = sentences[sen[0]]\n",
        "  for sen in sentences :\n",
        "    if sen == rel :\n",
        "      print(colored(sen,'white','on_green'), end = ' ')\n",
        "    else :\n",
        "      print(sen, end = ' ')\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKI_9s2gLhzz",
        "outputId": "e8312c4e-b89c-43f7-bc96-5220842f8f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[42m\u001b[37mWe are seeing an increasing number of errors with our payment services.\u001b[0m The\n",
            "issue has been reported by multiple users in the last 3 hours and this is affecting\n",
            "our revenue. We need to fix it immediately \n",
            "\n",
            "\u001b[42m\u001b[37mIt looks like the issue is limited only to visa credit cards\u001b[0m \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Second Approach = DistilBERT + Neural Network "
      ],
      "metadata": {
        "id": "7fX9IvyMHD_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, We get BERT embeddings for all sentences in our dataset : "
      ],
      "metadata": {
        "id": "paPSETItmuqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph1 = quora.iloc[:, 3]\n",
        "paragraph2 = quora.iloc[:, 4]\n",
        "corpus_1 = process(paragraph1)\n",
        "corpus_2 = process(paragraph2)\n",
        "embeddings_sen1 = model.encode(corpus_1)\n",
        "embeddings_sen2 = model.encode(corpus_2)"
      ],
      "metadata": {
        "id": "gCVTrrMRHNTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We save it, thus we won't need to run it every time :"
      ],
      "metadata": {
        "id": "OBrHno2Qm2Te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "encoding_data_file_quest1='encoding_quest1'\n",
        "encoding_data_file_quest2='encoding_quest2'\n",
        "\n",
        "with open(encoding_data_file_quest1, \"wb\") as fp:\n",
        "\t\tpickle.dump(vec1, fp)\n",
        "  \n",
        "with open(encoding_data_file_quest1, \"wb\") as fp:\n",
        "\t\tpickle.dump(vec1, fp)"
      ],
      "metadata": {
        "id": "ebLjDmCEIHal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(encoding_data_file_quest1, \"rb\") as fp:\n",
        "\t\tembeddings_sen1=pickle.load(fp)\n",
        "\t\n",
        "with open(encoding_data_file_quest2, \"rb\") as fp:   \n",
        "\t\tembeddings_sen2=pickle.load(fp)"
      ],
      "metadata": {
        "id": "oVf5sudfReKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_vec1 = np.asarray(embeddings_sen1, np.float32)\n",
        "train_vec2 = np.asarray(embeddings_sen2, np.float32)\n",
        "train_label = np.asarray(quora.iloc[:, 5],np.float32)"
      ],
      "metadata": {
        "id": "Z-CuWx0PLL9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create now our NN model :"
      ],
      "metadata": {
        "id": "v_vp6yr2nEfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = Input(shape=(768,))\n",
        "input2 = Input(shape=(768,))\n",
        "\n",
        "# we concatenate the two inputs = embeddings for each two sentences\n",
        "x = keras.layers.concatenate([input1,input2], axis=-1)\n",
        "\n",
        "# we add a three dense layers with three dropout layers for oferfitting reasons, the last Dense layer is to return the similarity score between -1 and 1  \n",
        "x = Dense(1024,activation='relu') (x)\n",
        "x = Dropout(0.5) (x)\n",
        "x = Dense(256,activation='relu') (x)\n",
        "x = Dropout(0.5) (x)\n",
        "x = Dense(64,activation='relu') (x)\n",
        "\n",
        "output = Dense(1,activation='sigmoid') (x)\n",
        "\n",
        "model = Model(inputs=[input1,input2],outputs=output)\n",
        "model.summary()\n",
        "\n",
        "# we compile our model\n",
        "model.compile(optimizer='rmsprop',\n",
        "  loss='binary_crossentropy',\n",
        "  metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR66oi9PLMFr",
        "outputId": "b70031fd-f5b2-492e-f844-e8e77d8c8ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 1536)         0           ['input_5[0][0]',                \n",
            "                                                                  'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1024)         1573888     ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 1024)         0           ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 256)          262400      ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 256)          0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 64)           16448       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 1)            65          ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,852,801\n",
            "Trainable params: 1,852,801\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training :"
      ],
      "metadata": {
        "id": "9U1AY3m5nrDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit([train_vec1, train_vec2], train_label, \n",
        "\tepochs=35,batch_size=200,\n",
        "\tvalidation_split=0.2) # we can add an early stopping param"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVS1bd23LMLb",
        "outputId": "b6b88ce4-26d5-40d3-9438-bcb4b994287b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "1618/1618 [==============================] - 87s 54ms/step - loss: 0.1904 - acc: 0.9227 - val_loss: 0.4351 - val_acc: 0.8280\n",
            "Epoch 2/35\n",
            "1618/1618 [==============================] - 87s 54ms/step - loss: 0.1891 - acc: 0.9238 - val_loss: 0.6063 - val_acc: 0.8286\n",
            "Epoch 3/35\n",
            "1618/1618 [==============================] - 86s 53ms/step - loss: 0.1857 - acc: 0.9250 - val_loss: 0.5689 - val_acc: 0.8284\n",
            "Epoch 4/35\n",
            "1618/1618 [==============================] - 86s 53ms/step - loss: 0.1849 - acc: 0.9256 - val_loss: 0.4779 - val_acc: 0.8273\n",
            "Epoch 5/35\n",
            "1618/1618 [==============================] - 86s 53ms/step - loss: 0.1826 - acc: 0.9269 - val_loss: 0.4286 - val_acc: 0.8279\n",
            "Epoch 6/35\n",
            "1618/1618 [==============================] - 87s 54ms/step - loss: 0.1810 - acc: 0.9272 - val_loss: 0.5538 - val_acc: 0.8284\n",
            "Epoch 7/35\n",
            "1618/1618 [==============================] - 88s 54ms/step - loss: 0.1782 - acc: 0.9288 - val_loss: 0.5389 - val_acc: 0.8274\n",
            "Epoch 8/35\n",
            "1618/1618 [==============================] - 89s 55ms/step - loss: 0.1764 - acc: 0.9299 - val_loss: 0.4917 - val_acc: 0.8272\n",
            "Epoch 9/35\n",
            "1618/1618 [==============================] - 91s 56ms/step - loss: 0.1762 - acc: 0.9293 - val_loss: 0.4840 - val_acc: 0.8289\n",
            "Epoch 10/35\n",
            "1618/1618 [==============================] - 91s 56ms/step - loss: 0.1755 - acc: 0.9304 - val_loss: 0.5337 - val_acc: 0.8281\n",
            "Epoch 11/35\n",
            "1618/1618 [==============================] - 88s 55ms/step - loss: 0.1724 - acc: 0.9319 - val_loss: 0.4997 - val_acc: 0.8292\n",
            "Epoch 12/35\n",
            "1618/1618 [==============================] - 89s 55ms/step - loss: 0.1719 - acc: 0.9321 - val_loss: 0.4721 - val_acc: 0.8280\n",
            "Epoch 13/35\n",
            "1618/1618 [==============================] - 89s 55ms/step - loss: 0.1690 - acc: 0.9330 - val_loss: 0.4423 - val_acc: 0.8251\n",
            "Epoch 14/35\n",
            "1618/1618 [==============================] - 87s 54ms/step - loss: 0.1686 - acc: 0.9333 - val_loss: 0.4534 - val_acc: 0.8276\n",
            "Epoch 15/35\n",
            "1618/1618 [==============================] - 88s 54ms/step - loss: 0.1675 - acc: 0.9345 - val_loss: 0.5540 - val_acc: 0.8289\n",
            "Epoch 16/35\n",
            "1618/1618 [==============================] - 93s 57ms/step - loss: 0.1658 - acc: 0.9354 - val_loss: 0.5823 - val_acc: 0.8291\n",
            "Epoch 17/35\n",
            "1618/1618 [==============================] - 94s 58ms/step - loss: 0.1637 - acc: 0.9365 - val_loss: 0.4360 - val_acc: 0.8302\n",
            "Epoch 18/35\n",
            "1618/1618 [==============================] - 92s 57ms/step - loss: 0.1623 - acc: 0.9366 - val_loss: 0.6217 - val_acc: 0.8307\n",
            "Epoch 19/35\n",
            "1618/1618 [==============================] - 85s 53ms/step - loss: 0.1614 - acc: 0.9372 - val_loss: 0.4930 - val_acc: 0.8293\n",
            "Epoch 20/35\n",
            "1618/1618 [==============================] - 85s 52ms/step - loss: 0.1606 - acc: 0.9379 - val_loss: 0.5429 - val_acc: 0.8287\n",
            "Epoch 21/35\n",
            "1618/1618 [==============================] - 85s 53ms/step - loss: 0.1574 - acc: 0.9391 - val_loss: 0.4879 - val_acc: 0.8288\n",
            "Epoch 22/35\n",
            "1618/1618 [==============================] - 86s 53ms/step - loss: 0.1578 - acc: 0.9392 - val_loss: 0.4352 - val_acc: 0.8266\n",
            "Epoch 23/35\n",
            "1618/1618 [==============================] - 87s 53ms/step - loss: 0.1554 - acc: 0.9400 - val_loss: 0.6002 - val_acc: 0.8305\n",
            "Epoch 24/35\n",
            "1618/1618 [==============================] - 88s 54ms/step - loss: 0.1539 - acc: 0.9410 - val_loss: 0.4422 - val_acc: 0.8302\n",
            "Epoch 25/35\n",
            "1618/1618 [==============================] - 87s 54ms/step - loss: 0.1522 - acc: 0.9417 - val_loss: 0.5321 - val_acc: 0.8309\n",
            "Epoch 26/35\n",
            "1618/1618 [==============================] - 88s 54ms/step - loss: 0.1510 - acc: 0.9419 - val_loss: 0.5012 - val_acc: 0.8291\n",
            "Epoch 27/35\n",
            "1618/1618 [==============================] - 88s 55ms/step - loss: 0.1505 - acc: 0.9429 - val_loss: 0.5032 - val_acc: 0.8279\n",
            "Epoch 28/35\n",
            "1618/1618 [==============================] - 90s 56ms/step - loss: 0.1499 - acc: 0.9422 - val_loss: 0.5462 - val_acc: 0.8301\n",
            "Epoch 29/35\n",
            "1618/1618 [==============================] - 88s 55ms/step - loss: 0.1475 - acc: 0.9437 - val_loss: 0.4910 - val_acc: 0.8286\n",
            "Epoch 30/35\n",
            "1618/1618 [==============================] - 89s 55ms/step - loss: 0.1469 - acc: 0.9442 - val_loss: 0.4794 - val_acc: 0.8300\n",
            "Epoch 31/35\n",
            "1618/1618 [==============================] - 90s 56ms/step - loss: 0.1459 - acc: 0.9441 - val_loss: 0.5090 - val_acc: 0.8282\n",
            "Epoch 32/35\n",
            "1618/1618 [==============================] - 90s 56ms/step - loss: 0.1441 - acc: 0.9454 - val_loss: 0.5216 - val_acc: 0.8302\n",
            "Epoch 33/35\n",
            "1618/1618 [==============================] - 91s 56ms/step - loss: 0.1445 - acc: 0.9453 - val_loss: 0.5873 - val_acc: 0.8311\n",
            "Epoch 34/35\n",
            "1618/1618 [==============================] - 92s 57ms/step - loss: 0.1426 - acc: 0.9455 - val_loss: 0.5227 - val_acc: 0.8305\n",
            "Epoch 35/35\n",
            "1618/1618 [==============================] - 90s 56ms/step - loss: 0.1425 - acc: 0.9460 - val_loss: 0.5692 - val_acc: 0.8307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference :**\n",
        "We apply the model on the given example in the assignment :"
      ],
      "metadata": {
        "id": "bD-VLMLbnuAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new = np.asarray(embeddings_distilbert, np.float32)\n",
        "n = len(embeddings_distilbert)\n",
        " \n",
        "queries = np.asarray(list(search_vect)*n, np.float32)\n",
        "preds = model.predict([new, queries], batch_size=200)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF195Z-4-jAP",
        "outputId": "28fa87d9-4107-4ce4-d952-502092bcadc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.1617627e-08],\n",
              "       [6.6597136e-07],\n",
              "       [6.6062169e-09],\n",
              "       [4.7373567e-07]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We sort the results and get the two more relevant conversations :"
      ],
      "metadata": {
        "id": "nnVoTxtdn7yV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_data_nn = []\n",
        "for index in np.argsort(preds[:,0])[:K]:\n",
        "    output_data_nn.append(paragraph[index])\n",
        "\n",
        "output_data_nn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHByByaXLqmE",
        "outputId": "61cc1c38-93a3-416c-d76c-a7607139b8d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It looks like the issue is limited only to visa credit cards',\n",
              " 'We are seeing an increasing number of errors with our payment services. The\\nissue has been reported by multiple users in the last 3 hours and this is affecting\\nour revenue. We need to fix it immediately']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We highlight the results :"
      ],
      "metadata": {
        "id": "uy-1HamdoBgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for elt in paragraph.values :\n",
        "    if elt in output_data_nn:\n",
        "        print(colored(elt,'white','on_green'))\n",
        "    else :\n",
        "        print(elt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO6mG1anLqrb",
        "outputId": "87605c16-76f2-4701-bd91-9d39b60059fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[42m\u001b[37mWe are seeing an increasing number of errors with our payment services. The\n",
            "issue has been reported by multiple users in the last 3 hours and this is affecting\n",
            "our revenue. We need to fix it immediately\u001b[0m\n",
            "We need to make improvements to our landing page to convey our new\n",
            "branding guidelines.\n",
            "\u001b[42m\u001b[37mIt looks like the issue is limited only to visa credit cards\u001b[0m\n",
            "We need to schedule a product meeting to discuss the new set of features and\n",
            "the roadmap.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We highlight the relevant sentence in search results :"
      ],
      "metadata": {
        "id": "4PBU5LxSWQau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for t in output_data_nn :\n",
        "  sentences = sent_tokenize(t)\n",
        "  sentences_ = process(sentences)\n",
        "  sentences_ = model.encode(sentences_)\n",
        "\n",
        "  new = np.asarray(sentences_, np.float32)\n",
        "  n = len(sentences_)\n",
        "  queries = np.asarray(list(search_vect)*n, np.float32)\n",
        "  preds = model.predict([new, queries], batch_size=200)\n",
        "  sen = np.argmax(preds[:,0])\n",
        "  rel = sentences[sen]\n",
        "\n",
        "  for sen in sentences :\n",
        "    if sen == rel :\n",
        "      print(colored(sen,'white','on_green'), end = ' ')\n",
        "    else :\n",
        "      print(sen, end = ' ')\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl0lrdn1LJ5R",
        "outputId": "88cdd22f-eb18-4e02-e9c3-d8154df9ab47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[42m\u001b[37mIt looks like the issue is limited only to visa credit cards\u001b[0m \n",
            "\n",
            "\u001b[42m\u001b[37mWe are seeing an increasing number of errors with our payment services.\u001b[0m The\n",
            "issue has been reported by multiple users in the last 3 hours and this is affecting\n",
            "our revenue. We need to fix it immediately \n",
            "\n"
          ]
        }
      ]
    }
  ]
}